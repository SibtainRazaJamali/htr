{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, datasets\n",
    "from torch.autograd import Variable\n",
    "from torchvision import transforms\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch import Tensor\n",
    "import utils\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "alphabet=' '+string.ascii_letters+string.punctuation+string.digits\n",
    "converter = utils.strLabelConverter(alphabet,ignore_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models.resnet import resnet50\n",
    "model=resnet50(pretrained=True)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "newmodel = nn.Sequential(*(list(model.children())[:-5]))\n",
    "block2=nn.Sequential(nn.Conv2d(256,128,kernel_size=(3,7),stride=(1,1),bias=False),\n",
    "              nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "              nn.Conv2d(128, 128, kernel_size=(3, 7), stride=(1, 1), bias=False),\n",
    "              nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "              nn.Conv2d(128, 512, kernel_size=(3, 7), stride=(1, 1), bias=False),\n",
    "              nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "              nn.ReLU(inplace=True),\n",
    "              nn.Conv2d(512, 512, kernel_size=(3, 7), stride=(1,1), bias=False),\n",
    "              nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "             )\n",
    "block3=nn.Sequential(nn.Conv2d(512, 128, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "                     nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                     nn.Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(0, 0), bias=False),\n",
    "                     nn.BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                     nn.Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "                     nn.BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                     nn.ReLU(inplace=True)\n",
    "                    )\n",
    "block4=nn.Sequential(nn.Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "                     nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                     nn.Conv2d(256, 256, kernel_size=(3, 3), bias=False),\n",
    "                     nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                     nn.Conv2d(256, 1024, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "                     nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n",
    "                     nn.ReLU(inplace=True),\n",
    "                     nn.Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), bias=False),\n",
    "                     nn.BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "                     \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CRNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CRNN,self).__init__()\n",
    "        self.cnn=newmodel\n",
    "        self.block2=block2\n",
    "        self.block3=block3\n",
    "        self.block4=block4\n",
    "        self.rnn_layer=nn.RNN(1024,hidden_size=256,num_layers=2,bidirectional=True)\n",
    "        self.num_classes = len(alphabet)\n",
    "        self.linear = nn.Linear(256 * 2,self.num_classes+1)\n",
    "        self.softmax = nn.LogSoftmax(dim=2)\n",
    "        self.abc=alphabet\n",
    "    def forward(self,X):\n",
    "        hidden = self.init_hidden(X.size(0), next(self.parameters()).is_cuda)\n",
    "        output=self.cnn(X)\n",
    "        #print (output.size())\n",
    "        output=self.block2(output)\n",
    "        #print (output.size())\n",
    "        output=self.block3(output)\n",
    "        #print (output.size())\n",
    "        output=self.block4(output)\n",
    "        #print (output.size())\n",
    "        conv = output.squeeze(2)\n",
    "        conv = conv.permute(2, 0, 1)\n",
    "        #print (conv.size())\n",
    "        seq,hidden=self.rnn_layer(conv,hidden)\n",
    "        \n",
    "        seq = self.linear(seq)\n",
    "        seq = self.softmax(seq)\n",
    "        #if not self.training:\n",
    "        #    seq = self.softmax(seq)\n",
    "        #    if decode:\n",
    "        #        seq = self.decode(seq)\n",
    "        return seq\n",
    "    def init_hidden(self, batch_size, gpu=True):\n",
    "        h0 = Variable(torch.zeros(2 * 2,batch_size,256))\n",
    "        if gpu:\n",
    "            h0 = h0.cuda()\n",
    "        return h0\n",
    "    \n",
    "\n",
    "    def pred_to_string(self, pred):\n",
    "        seq = []\n",
    "        for i in range(pred.shape[0]):\n",
    "            label = np.argmax(pred[i])\n",
    "            seq.append(label - 1)\n",
    "        out = []\n",
    "        for i in range(len(seq)):\n",
    "            if len(out) == 0:\n",
    "                if seq[i] != -1:\n",
    "                    out.append(seq[i])\n",
    "            else:\n",
    "                if seq[i] != -1 and seq[i] != seq[i - 1]:\n",
    "                    out.append(seq[i])\n",
    "        out = ''.join(self.abc[i] for i in out)\n",
    "        return out\n",
    "\n",
    "    def decode(self, pred):\n",
    "        pred = pred.permute(1, 0, 2).cpu().data.numpy()\n",
    "        seq = []\n",
    "        for i in range(pred.shape[0]):\n",
    "            seq.append(self.pred_to_string(pred[i]))\n",
    "        return seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import pandas as pd\n",
    "import string\n",
    "from torchvision import transforms\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import numpy as np\n",
    "class CustomDatasetFromImages(Dataset):\n",
    "    def __init__(self, csv_path,transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_path (string): path to csv file\n",
    "            img_path (string): path to the folder where images are\n",
    "            transform: pytorch transforms for transforms and tensor conversion\n",
    "        \"\"\"\n",
    "        self.data_info = pd.read_csv(csv_path, header=None,sep='|')\n",
    "        self.data_info=self.data_info#[:32]\n",
    "        self.image_arr = np.asarray(self.data_info.iloc[:, 0])\n",
    "        self.label = self.data_info.iloc[:, 1].apply(lambda x:torch.cuda.IntTensor(self.text_to_labels(x)))\n",
    "        self.seqLength=[]\n",
    "        for j in self.label:\n",
    "            self.seqLength.append(len(j))\n",
    "        self.transforms = transform\n",
    "        self.label_arr = pad_sequence(self.label,batch_first=True)\n",
    "        #print (self.label_arr)\n",
    "        self.data_len = len(self.data_info.index)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        single_image_name = self.image_arr[index]\n",
    "        img_as_img = Image.open(single_image_name)\n",
    "        img_as_img = img_as_img.convert('L')\n",
    "        img_as_tensor = self.transforms(img_as_img)\n",
    "        #print (img_as_tensor.size())\n",
    "        single_image_label = self.label_arr[index]\n",
    "        #print (single_image_label)\n",
    "        batch = {\"img\": img_as_tensor.cuda(), \"seq\": single_image_label,'seq_len':self.seqLength[index]}\n",
    "        return batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_len\n",
    "    def text_to_labels(self,text):\n",
    "        ret = []\n",
    "        for char in text:\n",
    "            ret.append(alphabet.find(char))\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformations = transforms.Compose([transforms.Resize((90,540)),transforms.ToTensor()])\n",
    "data_set=CustomDatasetFromImages('htr_data.csv',transform=transformations)\n",
    "mn_dataset_loader = torch.utils.data.DataLoader(dataset=data_set,batch_size=63,shuffle=False)\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear or type(m)==nn.Conv2d:\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.9 * len(mn_dataset_loader))\n",
    "test_size = len(mn_dataset_loader) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(mn_dataset_loader, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10368"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset)*64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/180 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 2.7844668640030754\n",
      "2 2.506257116794586\n",
      "3 2.418787129720052\n",
      "4 2.38413626882765\n",
      "5 2.316758852534824\n",
      "6 2.3656846920649213\n",
      "7 2.3521887010998195\n",
      "8 2.298591024345822\n",
      "9 2.2927293512556286\n",
      "10 2.325178152985043\n",
      "11 2.2952105601628623\n",
      "12 2.2836824019749957\n",
      "13 2.268980529573229\n",
      "14 2.2752033405833774\n",
      "15 2.2560946663220722\n",
      "16 2.264959670437707\n",
      "17 2.252026723490821\n",
      "18 2.2575770378112794\n",
      "19 2.2488665368821885\n",
      "20 2.2470244619581434\n",
      "21 2.2539031128088634\n",
      "22 2.2475311199824017\n",
      "23 2.258820797337426\n",
      "24 2.2546579082806906\n",
      "25 2.2529238051838343\n",
      "26 2.243513778845469\n",
      "27 2.242825946542952\n",
      "28 2.234832379553053\n",
      "29 2.23793809082773\n",
      "30 2.2277292013168335\n",
      "31 2.2357754680845474\n",
      "32 2.2457206500901115\n",
      "33 2.23326736357477\n",
      "34 2.228330859210756\n",
      "35 2.2260054296917384\n",
      "36 2.2228798296716477\n",
      "37 2.223023058970769\n",
      "38 2.2178168813387553\n",
      "39 2.217941257688734\n",
      "40 2.221052204238044\n"
     ]
    }
   ],
   "source": [
    "cmodel = CRNN().cuda()\n",
    "#print (output.size())cmodel.apply(init_weights)\n",
    "criterion = nn.CTCLoss(blank=0)\n",
    "optimizer = torch.optim.RMSprop(cmodel.parameters(), lr=0.0005)\n",
    "iterator = tqdm(mn_dataset_loader)\n",
    "#print (iterator)\n",
    "epoch=0\n",
    "while True:\n",
    "    running_loss = 0.0\n",
    "    if epoch==500:\n",
    "        break\n",
    "    step=0\n",
    "    for item in mn_dataset_loader:\n",
    "        step+=1\n",
    "        images = Variable(item['img'])\n",
    "        labels = Variable(item['seq'])\n",
    "        #print (images.size())\n",
    "        #print (labels.size())\n",
    "        optimizer.zero_grad()\n",
    "        outputs = cmodel(images)\n",
    "        #if step%10==0:\n",
    "        #    p=outputs[0]\n",
    "\n",
    "        #    decodes, _ = tf.nn.ctc_beam_search_decoder(inputs=p.cpu().detach().numpy(),sequence_length=99*np.ones(1), merge_repeated=True)\n",
    "        #    with tf.Session(config = tf.ConfigProto(device_count = {'GPU': 0})) as sess:\n",
    "        #        t_ = sess.run(decodes)[0].values\n",
    "        #        char_list = []\n",
    "        #        for i in range(len(sess.run(decodes)[0].values)):\n",
    "        #                if t_[i] != 0 and (not (i > 0 and t_[i - 1] == t_[i])):\n",
    "        #                    char_list.append(alphabet[t_[i] - 1])\n",
    "        #        sim_pred = ''.join(char_list)\n",
    "        #        print (sim_pred)\n",
    "        pred_lens = Variable(Tensor([outputs.size(0)] * 63).int())\n",
    "        label_lens = Variable(item['seq_len'].int())\n",
    "        loss = criterion(outputs,labels,pred_lens,label_lens)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "            \n",
    "    epoch+=1\n",
    "    print(epoch,running_loss/step)\n",
    "    #n, preds = outputs.max(2)\n",
    "    #print (n)\n",
    "    #print ('done')\n",
    "    #print (preds)\n",
    "    #preds=\n",
    "    #preds = preds.squeeze(2)\n",
    "    #print (preds)\n",
    "    #preds = preds.contiguous().view(-1)\n",
    "    #preds_size = Variable(torch.Inteduction='mean'Tensor([preds.size(0)]))\n",
    "    #raw_pred = converter.decode(preds.data, preds_size.data, raw=False)\n",
    "    #print (len(raw_pred))\n",
    "    #sim_pred = model.decode(outputs)\n",
    "    #print (raw_pred)\n",
    "    #print ('\\n')\n",
    "    #print (raw_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
